{
  "session_timestamp": "20250831_193700",
  "config": {
    "model_name": "google/gemma-2-2b-it",
    "dataset_repo": "miladmim/slim-orca-dedup-chat-50k-persian",
    "max_length": 1024,
    "lora_r": 8,
    "lora_alpha": 16,
    "lora_dropout": 0.05,
    "lora_target_modules": [
      "q_proj",
      "v_proj"
    ],
    "num_epochs": 2,
    "batch_size": 4,
    "gradient_accumulation_steps": 8,
    "learning_rate": 0.0005,
    "warmup_ratio": 0.03,
    "eval_steps": 500,
    "save_steps": 500,
    "session_timestamp": "20250831_193700"
  },
  "dataset_stats": {
    "original_size": 40458,
    "after_cleaning": 39943,
    "final_pairs": 39943,
    "roles_found": [
      "",
      "assistant",
      "دستیار",
      "کاربر",
      "user",
      "system"
    ],
    "role_distribution": {
      "system": 40459,
      "user": 40023,
      "assistant": 40413,
      "": 5,
      "کاربر": 1,
      "دستیار": 1
    }
  },
  "model_info": {
    "trainable_params": 1597440,
    "total_params": 2615939328,
    "trainable_ratio": 0.0006106563645806391
  },
  "training_metrics": {
    "final_train_loss": 1.2078400841943018,
    "training_duration_seconds": 18034.446513175964,
    "test_eval_loss": 1.1241627931594849,
    "test_perplexity": 3.077639149486208
  },
  "paths": {
    "output_dir": "./gemma_lora/gemma2b_it_lora_r8_alpha16_20250831_193700",
    "adapter_dir": "./gemma_lora/gemma2b_it_lora_r8_alpha16_20250831_193700/lora_adapter",
    "config_file": "./gemma_lora/config_20250831_193700.json",
    "stats_file": "./gemma_lora/dataset_stats_20250831_193700.json",
    "loss_curve": "./gemma_lora/gemma2b_it_lora_r8_alpha16_20250831_193700/loss_curve.png"
  }
}